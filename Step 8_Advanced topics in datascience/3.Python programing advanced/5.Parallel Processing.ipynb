{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've seen how the CPU runs code in sequence, and how control flow statements (like if and else) can change the order in which it executes statements. However, `we can also write programs that execute more than one instruction at a time`. **A multi-core CPU has the ability to run multiple instructions simultaneously.** The desire to take advantage of modern, multi-core CPUs has given rise to a technique called **parallel processing**, which is very useful in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel processing can be powerful, but it also presents many unique challenges. `When multiple processes are sharing data, it's important to manage which process has access to the data and when so that it doesn't become corrupted`. It's also important to think the execution of parallel processes through carefully, `because executing multiple instructions at once can potentially introduce tricky bugs.` Learning to manage these factors will help you write very powerful code that does quick and meaningful data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using Mutable Values for Changing Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, `some values are immutable`, such as integers. This means that we can't change them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data structures we've worked with (like dictionaries and lists) are mutable, so they're useful for representing information that changes.**` Mutable variables are especially useful in parallel processing because we often want to share and edit the same data between different processes.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Create an instance of the Counter class called counter.\n",
    "\n",
    "* Call counter.get_count() to get the initial value of the counter, and store it in initial_count.\n",
    "\n",
    "* Call count_up_100000 with counter as its argument.\n",
    "\n",
    "* Call counter.get_count() to get the final value of the counter, and store it in final_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter():\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "    def increment(self):\n",
    "        self.count += 1\n",
    "    def get_count(self):\n",
    "        return self.count\n",
    "    \n",
    "def count_up_100000(counter):\n",
    "    for i in range(100000):\n",
    "        counter.increment()\n",
    "\n",
    "counter = Counter()\n",
    "initial_count = counter.get_count()\n",
    "count_up_100000(counter)\n",
    "final_count = counter.get_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multithreading Multiple Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the last screen, we counted from 0 to 100000 using a Counter instance. Creating this instance, calling the function, and incrementing the counter all happened in one process. `Every instruction in the process executed one after the other. We can also run multiple processes at once, however. We often refer to this technique as multithreading.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A thread is one path of execution in a program. We typically have one \"main thread\" that we think of as our single process program. We can also create new threads, though, and run them concurrently with the main thread.` **`To do this in Python, we use the threading module. Specifically, we can use threading.Thread() to create an instance of the Thread class, which executes a given function as a separate process.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a Thread instance that runs the count_up_100000 function with counter as an argument, we write:\n",
    "import threading\n",
    "\n",
    "thread = threading.Thread(target=count_up_100000, args=[counter])\n",
    "\n",
    "# Then we start the thread:\n",
    "\n",
    "thread.start()\n",
    "\n",
    "# Next, we \"join\" the thread so that when it's finished executing, it \"joins\" with the main thread by terminating:\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The main thread will wait until the other thread has finished executing before moving past the thread.join() call`. **`Waiting for a condition like the termination of a thread is called blocking.`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "count_thread = threading.Thread(target=count_up_100000, args=[counter])\n",
    "count_thread.start()\n",
    "count_thread.join()\n",
    "after_join = counter.get_count()\n",
    "print(after_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Determinism of Program Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`In programming, we say that a program is deterministic if` **`we can precisely predict its output for a particular input`**. `Most single-threaded operations are deterministic because we can walk through the code for any input step by step, and predict the output.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine that you call your friend a few hours after he started counting to ask what number he's on. He may be at 1000, or 10000, or 25392. It's impossible to know for sure, and this is analogous to measuring the value of our counter before we've joined the counting thread. We can't predict this value because we don't know how many iterations of the counting loop will have been executed at the time of our reading. `When we can't reliably predict the outcome of running a piece of code, we call that code nondeterministic.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61195\n",
      "22319\n",
      "16798\n"
     ]
    }
   ],
   "source": [
    "def conduct_trial():\n",
    "    counter = Counter()\n",
    "    count_thread = threading.Thread(target=count_up_100000, args=[counter])\n",
    "    count_thread.start()\n",
    "    intermediate_value = counter.get_count()\n",
    "    count_thread.join()\n",
    "    return intermediate_value\n",
    "\n",
    "trial1 = conduct_trial()\n",
    "print(trial1)\n",
    "trial2 = conduct_trial()\n",
    "print(trial2)\n",
    "trial3 = conduct_trial()\n",
    "print(trial3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Using Locks to Enforce Determinism in Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Multithreading is nondeterministic by nature, but there are ways to combat that nondeterminism. The easiest and most common way to make multithreading more predictable is through the use of threading.Lock. A lock is a way to conditionally block the execution of some threads. At any given time, we can think of a lock as being either available or acquired. A thread can acquire an available lock, but if a thread tries to acquire an acquired lock (that another thread is using), it will be blocked until that lock becomes available.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Wrap the inner for loop in count_up_100000 inside lock.acquire() and lock.release() so that nobody can acquire the lock unless the counter value is a multiple of 10.\n",
    "\n",
    "* In conduct_trial(), wrap the call to counter.get_count() inside lock.acquire() and lock.release() so that the main thread can only read the counter value at multiples of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26180\n",
      "16560\n",
      "15200\n"
     ]
    }
   ],
   "source": [
    "def count_up_100000(counter, lock):\n",
    "    for i in range(10000):\n",
    "        lock.acquire()\n",
    "        for i in range(10):\n",
    "            counter.increment()\n",
    "        lock.release()\n",
    "\n",
    "def conduct_trial():\n",
    "    counter = Counter()\n",
    "    lock = threading.Lock()\n",
    "    count_thread = threading.Thread(target=count_up_100000, args=[counter, lock])\n",
    "    count_thread.start()\n",
    "    lock.acquire()\n",
    "    intermediate_value = counter.get_count()\n",
    "    lock.release()\n",
    "    count_thread.join()\n",
    "    return intermediate_value\n",
    "\n",
    "trial1 = conduct_trial()\n",
    "print(trial1)\n",
    "trial2 = conduct_trial()\n",
    "print(trial2)\n",
    "trial3 = conduct_trial()\n",
    "print(trial3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Counting in Two Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we want to count to 200000. We can do this in two stages:\n",
    "\n",
    "* Increment counter 100000 times\n",
    "* Increment counter 100000 times again\n",
    "\n",
    "This approach will produce interesting results because the operation will behave differently if we split it up among multiple threads. First, let's implement this behavior using only the main thread. Try to predict the outcome before running your code. Remember that we're implementing a single-threaded solution on this screen, so the outcome should be deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Call count_up_100000() twice, using counter as an argument each time.\n",
    "\n",
    "* Use counter.get_count() to assign the value of our counter after the two function calls to final_count.\n",
    "\n",
    "* Print final_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "def count_up_100000(counter):\n",
    "    for i in range(100000):\n",
    "        counter.increment()\n",
    "\n",
    "counter = Counter()\n",
    "def count_up_100000(counter):\n",
    "    for i in range(100000):\n",
    "        counter.increment()\n",
    "\n",
    "counter = Counter()\n",
    "count_up_100000(counter)\n",
    "count_up_100000(counter)\n",
    "final_count = counter.get_count()\n",
    "print(final_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Counting Once on Two Different Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement a multi-threaded implementation to count to 200000. We've defined a conduct_trial() function that counts to 200000 with two threads, each of which increments the counter 100000 times. It's important that both of the threads start at the same time, and are joined at the same time. For this experiment, we want the threads to execute in parallel so we can make observations about how they behave in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Call .join() on each of the counting threads in the conduct_trial() function. It's critical that both join calls occur after both threads have already started.\n",
    "\n",
    "* Conduct three trials by calling conduct_trial() three separate times. Assign the results to trial1, trial2, and trial3, and print those values to observe the results of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180418\n",
      "175700\n",
      "136765\n"
     ]
    }
   ],
   "source": [
    "def count_up_100000(counter):\n",
    "    for i in range(100000):\n",
    "        \n",
    "        counter.increment()\n",
    "\n",
    "def conduct_trial():\n",
    "    counter = Counter()\n",
    "    count_thread1 = threading.Thread(target=count_up_100000, args=[counter])\n",
    "    count_thread2 = threading.Thread(target=count_up_100000, args=[counter])\n",
    "\n",
    "    count_thread1.start()\n",
    "    count_thread2.start()\n",
    "\n",
    "    # Join the threads here\n",
    "    count_thread1.join()\n",
    "    count_thread2.join()\n",
    "    \n",
    "    final_count = counter.get_count()\n",
    "    return final_count\n",
    "\n",
    "trial1 = conduct_trial()\n",
    "print(trial1)\n",
    "trial2 = conduct_trial()\n",
    "print(trial2)\n",
    "trial3 = conduct_trial()\n",
    "print(trial3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Imitating Atomicity With Locks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`An atomic operation is an operation that finishes executing before any other operation can occur, regardless of multithreading.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* In the __init__ method of the Counter class, add a lock property.\n",
    "\n",
    "* Before the first line of the counter.increment() method, acquire the lock.\n",
    "\n",
    "* After the last line of the counter.increment() method, release the lock.\n",
    "\n",
    "* Conduct three trials by calling conduct_trial() three separate times. Assign the results to trial1, trial2, and trial3, and print those values to observe the results of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "200000\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "class Counter():\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.lock = threading.Lock()\n",
    "    def increment(self):\n",
    "        self.lock.acquire()\n",
    "        old_count = self.count\n",
    "        self.count = old_count + 1\n",
    "        self.lock.release()\n",
    "    def get_count(self):\n",
    "        return self.count\n",
    "\n",
    "def count_up_100000(counter):\n",
    "    for i in range(100000):\n",
    "        counter.increment()\n",
    "\n",
    "def conduct_trial():\n",
    "    counter = Counter()\n",
    "    count_thread1 = threading.Thread(target=count_up_100000, args=[counter])\n",
    "    count_thread2 = threading.Thread(target=count_up_100000, args=[counter])\n",
    "\n",
    "    count_thread1.start()\n",
    "    count_thread2.start()\n",
    "\n",
    "    count_thread1.join()\n",
    "    count_thread2.join()\n",
    "\n",
    "    final_count = counter.get_count()\n",
    "    return final_count\n",
    "\n",
    "trial1 = conduct_trial()\n",
    "print(trial1)\n",
    "trial2 = conduct_trial()\n",
    "print(trial2)\n",
    "trial3 = conduct_trial()\n",
    "print(trial3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We've seen some of the problems that parallel processing can introduce, such as nonatomicity and nondeterminism. In data science, it's important to maintain the integrity of our data, and a multithreaded environment is no exception. By using tools like locks to enforce atomicity and determinism, we can protect resources shared between threads, and ensure that delegating tasks between threads doesn't introduce unexpected bugs into our code.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
