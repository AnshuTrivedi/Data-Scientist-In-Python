{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Testing quality of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to test the quality of your model is to:\n",
    "\n",
    "*  **split the dataset into 2 partitions:**\n",
    "   * the **training set:** contains the majority of the rows (75%)\n",
    "   * the **test set:** contains the remaining minority of the rows (25%)\n",
    "\n",
    "* **use the rows in the training set to predict the price value for the rows in the test set**\n",
    "\n",
    "   add new column named predicted_price to the test set\n",
    "\n",
    "* **compare the predicted_price values with the actual price values in the test set to see how accurate the predicted values were.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This validation process, where we use the training set to make predictions and the test set to predict values for, is known as train/test validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Whenever you're performing machine learning, you want to perform validation of some kind to ensure that your machine learning model can make good predictions on new data.` While train/test validation isn't perfect, we'll use it to understand the validation process, to select an error metric,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Within the predict_price function, change the Dataframe that temp_df is assigned to. Change it from dc_listings to train_df, so only the training set is used.\n",
    "* Use the Series method apply to pass all of the values in the accommodates column from test_df through the predict_price function.\n",
    "* Assign the resulting Series object to the predicted_price column in test_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>room_type</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92%</td>\n",
       "      <td>91%</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>$160.00</td>\n",
       "      <td>$115.00</td>\n",
       "      <td>$100.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>38.890046</td>\n",
       "      <td>-77.002808</td>\n",
       "      <td>Washington</td>\n",
       "      <td>20003</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90%</td>\n",
       "      <td>100%</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$350.00</td>\n",
       "      <td>$100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>38.880413</td>\n",
       "      <td>-76.990485</td>\n",
       "      <td>Washington</td>\n",
       "      <td>20003</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90%</td>\n",
       "      <td>100%</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "      <td>38.955291</td>\n",
       "      <td>-76.986006</td>\n",
       "      <td>Hyattsville</td>\n",
       "      <td>20782</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$95.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>38.872134</td>\n",
       "      <td>-77.019639</td>\n",
       "      <td>Washington</td>\n",
       "      <td>20024</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92%</td>\n",
       "      <td>67%</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$50.00</td>\n",
       "      <td>$15.00</td>\n",
       "      <td>$450.00</td>\n",
       "      <td>7</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "      <td>38.996382</td>\n",
       "      <td>-77.041541</td>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>20910</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  host_response_rate host_acceptance_rate  host_listings_count  accommodates  \\\n",
       "0                92%                  91%                   26             4   \n",
       "1                90%                 100%                    1             6   \n",
       "2                90%                 100%                    2             1   \n",
       "3               100%                  NaN                    1             2   \n",
       "4                92%                  67%                    1             4   \n",
       "\n",
       "         room_type  bedrooms  bathrooms  beds    price cleaning_fee  \\\n",
       "0  Entire home/apt       1.0        1.0   2.0  $160.00      $115.00   \n",
       "1  Entire home/apt       3.0        3.0   3.0  $350.00      $100.00   \n",
       "2     Private room       1.0        2.0   1.0   $50.00          NaN   \n",
       "3     Private room       1.0        1.0   1.0   $95.00          NaN   \n",
       "4  Entire home/apt       1.0        1.0   1.0   $50.00       $15.00   \n",
       "\n",
       "  security_deposit  minimum_nights  maximum_nights  number_of_reviews  \\\n",
       "0          $100.00               1            1125                  0   \n",
       "1              NaN               2              30                 65   \n",
       "2              NaN               2            1125                  1   \n",
       "3              NaN               1            1125                  0   \n",
       "4          $450.00               7            1125                  0   \n",
       "\n",
       "    latitude  longitude           city zipcode state  \n",
       "0  38.890046 -77.002808     Washington   20003    DC  \n",
       "1  38.880413 -76.990485     Washington   20003    DC  \n",
       "2  38.955291 -76.986006    Hyattsville   20782    MD  \n",
       "3  38.872134 -77.019639     Washington   20024    DC  \n",
       "4  38.996382 -77.041541  Silver Spring   20910    MD  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "dc_listings=pd.read_csv('dc_airbnb.csv')\n",
    "\n",
    "dc_listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$160.00', '$350.00', '$50.00', '$95.00', '$99.00', '$100.00',\n",
       "       '$38.00', '$71.00', '$97.00', '$55.00', '$60.00', '$52.00',\n",
       "       '$23.00', '$200.00', '$40.00', '$135.00', '$225.00', '$129.00',\n",
       "       '$149.00', '$150.00', '$175.00', '$239.00', '$65.00', '$80.00',\n",
       "       '$250.00', '$138.00', '$94.00', '$283.00', '$127.00', '$79.00',\n",
       "       '$110.00', '$480.00', '$372.00', '$125.00', '$89.00', '$90.00',\n",
       "       '$400.00', '$35.00', '$130.00', '$45.00', '$64.00', '$59.00',\n",
       "       '$74.00', '$69.00', '$49.00', '$157.00', '$128.00', '$102.00',\n",
       "       '$195.00', '$120.00', '$249.00', '$88.00', '$85.00', '$215.00',\n",
       "       '$299.00', '$309.00', '$375.00', '$180.00', '$337.00', '$126.00',\n",
       "       '$199.00', '$165.00', '$115.00', '$569.00', '$198.00', '$311.00',\n",
       "       '$167.00', '$104.00', '$159.00', '$190.00', '$246.00', '$450.00',\n",
       "       '$234.00', '$109.00', '$87.00', '$210.00', '$300.00', '$189.00',\n",
       "       '$269.00', '$119.00', '$295.00', '$155.00', '$229.00', '$75.00',\n",
       "       '$105.00', '$259.00', '$139.00', '$329.00', '$168.00', '$290.00',\n",
       "       '$725.00', '$145.00', '$399.00', '$429.00', '$179.00', '$43.00',\n",
       "       '$185.00', '$220.00', '$289.00', '$81.00', '$194.00', '$629.00',\n",
       "       '$571.00', '$339.00', '$170.00', '$245.00', '$140.00', '$70.00',\n",
       "       '$124.00', '$96.00', '$349.00', '$78.00', '$72.00', '$279.00',\n",
       "       '$154.00', '$58.00', '$68.00', '$103.00', '$324.00', '$319.00',\n",
       "       '$209.00', '$36.00', '$1,000.00', '$132.00', '$56.00', '$219.00',\n",
       "       '$108.00', '$118.00', '$310.00', '$188.00', '$116.00', '$53.00',\n",
       "       '$800.00', '$41.00', '$42.00', '$39.00', '$214.00', '$84.00',\n",
       "       '$83.00', '$207.00', '$230.00', '$495.00', '$158.00', '$298.00',\n",
       "       '$111.00', '$193.00', '$63.00', '$93.00', '$312.00', '$600.00',\n",
       "       '$340.00', '$265.00', '$240.00', '$98.00', '$112.00', '$162.00',\n",
       "       '$73.00', '$599.00', '$62.00', '$720.00', '$178.00', '$275.00',\n",
       "       '$280.00', '$1,250.00', '$390.00', '$497.00', '$330.00', '$164.00',\n",
       "       '$500.00', '$117.00', '$121.00', '$475.00', '$217.00', '$320.00',\n",
       "       '$1,300.00', '$47.00', '$114.00', '$380.00', '$850.00', '$650.00',\n",
       "       '$260.00', '$33.00', '$113.00', '$169.00', '$34.00', '$44.00',\n",
       "       '$67.00', '$30.00', '$192.00', '$46.00', '$550.00', '$325.00',\n",
       "       '$474.00', '$775.00', '$595.00', '$201.00', '$975.00', '$122.00',\n",
       "       '$161.00', '$415.00', '$515.00', '$439.00', '$172.00', '$203.00',\n",
       "       '$418.00', '$222.00', '$143.00', '$142.00', '$525.00', '$136.00',\n",
       "       '$177.00', '$176.00', '$148.00', '$107.00', '$174.00', '$66.00',\n",
       "       '$700.00', '$499.00', '$196.00', '$695.00', '$101.00', '$137.00',\n",
       "       '$1,200.00', '$134.00', '$77.00', '$146.00', '$32.00', '$156.00',\n",
       "       '$92.00', '$379.00', '$228.00', '$57.00', '$520.00', '$395.00',\n",
       "       '$91.00', '$223.00', '$235.00', '$86.00', '$10.00', '$76.00',\n",
       "       '$82.00', '$37.00', '$1,500.00', '$333.00', '$51.00', '$28.00',\n",
       "       '$54.00', '$20.00', '$398.00', '$270.00', '$679.00', '$285.00',\n",
       "       '$2,822.00', '$144.00', '$163.00', '$25.00', '$2,000.00',\n",
       "       '$900.00', '$749.00', '$345.00', '$425.00', '$171.00', '$750.00',\n",
       "       '$152.00', '$48.00', '$258.00', '$315.00', '$181.00', '$31.00',\n",
       "       '$267.00', '$1,400.00', '$268.00', '$435.00', '$205.00', '$440.00',\n",
       "       '$253.00', '$191.00', '$133.00', '$212.00', '$535.00', '$123.00',\n",
       "       '$186.00', '$293.00', '$365.00'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean price column\n",
    "dc_listings['price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings['price']=dc_listings['price'].str.replace('$','').str.replace(',','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    160.0\n",
       "1    350.0\n",
       "2     50.0\n",
       "3     95.0\n",
       "4     50.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3723, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset in train and test dataset\n",
    "train_df=dc_listings.iloc[0:2792]\n",
    "test_df=dc_listings.iloc[2792:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(new_listing):\n",
    "    ## DataFrame.copy() performs a deep copy\n",
    "    temp_df = dc_listings.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbor_prices.mean()\n",
    "    return(predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained using train_df dataset\n",
    "\n",
    "def predict_price(new_listing):\n",
    "    ## DataFrame.copy() performs a deep copy\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbor_prices.mean()\n",
    "    return(predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2792    104.0\n",
       "2793    177.4\n",
       "2794    145.8\n",
       "2795    177.4\n",
       "2796    187.2\n",
       "Name: predicted_price, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict price using test_df dataset\n",
    "\n",
    "test_df['predicted_price']=test_df['accommodates'].apply(predict_price)\n",
    "test_df['predicted_price'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Error Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now need a metric that quantifies how good the predictions were on the test set. This class of metrics is called an error metric.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As the name suggests, an error metric quantifies how inaccurate our predictions were from the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We could start by calculating the difference between each predicted and actual value and then averaging these differences. This is referred to as **mean error** but isn't an effective error metric for most cases. Mean error treats a positive difference differently than a negative difference, but we're really interested in how far off the prediction is in either the positive or negative direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can instead use the **mean absolute error**, where we compute the absolute value of each error before we average all the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $MAE = \\frac{1}{n} \\sum_{k=1}^{n} \\lvert (actual_1 - predicted_1) \\rvert + \\cdots + \\lvert (actual_n - predicted_n) \\rvert$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Use numpy.absolute() to calculate the mean absolute error between predicted_price and price.\n",
    "* Assign the MAE to mae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56.29001074113876"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    " \n",
    "test_df['error']=np.absolute(test_df['predicted_price']-test_df['price'])\n",
    "mae=test_df['error'].mean()\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `For many prediction tasks, we want to penalize predicted values that are further away from the actual value far more than those closer to the actual value`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can instead take the **mean of the squared error values,** which is called the mean squared error or MSE for short. The MSE makes the gap between the predicted and actual values more clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $MSE = \\frac{1}{n} \\sum_{k=1}^{n} (actual_1 - predicted_1)^{2} + \\cdots + (actual_n - predicted_n)^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Calculate the MSE value between the predicted_price and price columns and assign to mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18646.525370569325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['squared_error']=(test_df['predicted_price']-test_df['price'])**2\n",
    "mse=test_df['squared_error'].mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training another model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we trained achieved a mean squared error of around 18646.5. Is this a high or a low mean squared error value? What does this tell us about the quality of the predictions and the model? By itself, the mean squared error value for a single model isn't all that useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The units of mean squared error in our case is dollars squared (not dollars), which makes it hard to reason about intuitively as well. We can, however, train another model and then compare the mean squared error values to see which model performs better on a relative basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**low error metric means that the gap between the predicted list price and actual list price values is low while a high error metric means the gap is high.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Modify the predict_price function to the right to use the bathrooms column instead of the accommodates column to make predictions.\n",
    "* Apply the function to test_df and assign the resulting Series object containing the predicted price values to the predicted_price column in test_df.\n",
    "* Calculate the squared error between the price and predicted_price columns in test_df and assign the resulting Series object to the squared_error column in test_df.\n",
    "* Calculate the mean of the squared_error column in test_df and assign to mse.\n",
    "* Use the print function or the variables inspector to display the MSE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(new_listing):\n",
    "    ## DataFrame.copy() performs a deep copy\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['bathrooms'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbor_prices.mean()\n",
    "    return(predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_df['predicted_price'] = test_df['bathrooms'].apply(lambda x: predict_price(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_df['squarred_error']=(test_df['predicted_price']-test_df['price'])**(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=test_df['squared_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18646.525370569325"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **While comparing MSE values helps us identify which model performs better on a relative basis, it doesn't help us understand if the performance is good enough in general.** This is because the units of the MSE metric are squared (in this case, dollars squared)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Root mean squared error is an error metric whose units are the base unit (in our case, dollars). RMSE for short, this error metric is calculated by taking the square root of the MSE value:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the RMSE value uses the same units as the target column, we can understand how far off in real dollars we can expect the model to perform.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $RMSE = \\sqrt{MSE}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Calculate the RMSE value of the model we trained using the bathrooms column and assign it to rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136.55228072269364"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse=mse**(1/2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Comparing MAE and RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model achieved an RMSE value of approximately 135.6, which implies that we should expect for the model to be off by 135.6 dollars on average for the predicted price values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These individual error metrics are helpful for comparing models. **To better understand a specific model, we can compare multiple error metrics for the same model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * $ MAE = \\frac{1}{n} \\sum_{k=1}^{n} \\lvert (actual_1 - predicted_1) \\rvert + \\cdots + \\lvert (actual_n - predicted_n) \\rvert $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* you'll notice that that the **differences between predicted and actual values grow linearly.** A prediction that's off by 10 dollars has a 10 times higher error than a prediction that's off by 1 dollar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * $ RMSE = \\sqrt { \\frac{ \\sum_{k=1}^{n} (actual_1 - predicted_1)^2 + \\cdots + (actual_n - predicted_n)^2 } {n} } $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* you'll notice that each error is squared before the square root of the sum of all the errors is taken. This means that the **individual errors grows quadratically and has a different effect on the final RMSE value**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Calculate the MAE for errors_one and assign to mae_one.\n",
    "* Calculate the RMSE for errors_one and assign to rmse_one.\n",
    "* Calculate the MAE for errors_two and assign to mae_two.\n",
    "* Calculate the RMSE for errors_two and assign to rmse_two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_one = pd.Series([5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10])\n",
    "errors_two = pd.Series([5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_one=errors_one.sum()/len(errors_one)\n",
    "rmse_one=((errors_one**2).sum()/len(errors_one))**(1/2)\n",
    "mae_two=errors_two.sum()/len(errors_two)\n",
    "rmse_two=((errors_two**2).sum()/len(errors_two))**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the MAE (7.5) to RMSE (7.9056941504209481) ratio was about 1:1 for the first list of errors, the MAE (62.5) to RMSE (235.82302686548658) ratio was closer to 1:4 for the second list of errors.**In general, we should expect that the MAE value be much less than the RMSE value.** The only difference between the 2 sets of errors is the extreme 1000 value in errors_two instead of 10. When we're working with larger data sets, we can't inspect each value to understand if there's one or some outliers or if all of the errors are systematically higher.**Looking at the ratio of MAE to RMSE can help us understand if there are large but infrequent errors.** You can read more about comparing MAE and RMSE in this wonderful post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
