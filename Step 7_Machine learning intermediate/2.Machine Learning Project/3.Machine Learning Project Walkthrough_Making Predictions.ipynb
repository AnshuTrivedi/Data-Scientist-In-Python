{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We spent the last 2 missions cleaning and preparing a dataset that contains data on loans made to members of Lending Club.` Our eventual goal is to generate features from the data, which can feed into a machine learning algorithm.` The algorithm will make predictions about whether or not a loan will be paid off on time, which is contained in the loan_status column of the clean dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we prepared the data,**`we removed columns that had data leakage issues, contained redundant information, or required additional processing to turn into useful features. We cleaned features that had formatting issues, and converted categorical columns to dummy variables.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last mission, we noticed that there's a `class imbalance in our target column,` loan_status. There are about 6 times as many loans that were paid off on time (positive case, label of 1) than those that weren't (negative case, label of 0). Imbalances can cause issues with many machine learning algorithms, where they appear to have high accuracy, but actually aren't learning from the training data. Because of its potential to cause issues, we need to keep the class imbalance in mind as we build machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37675 entries, 0 to 37674\n",
      "Data columns (total 38 columns):\n",
      "loan_amnt                              37675 non-null float64\n",
      "int_rate                               37675 non-null float64\n",
      "installment                            37675 non-null float64\n",
      "emp_length                             37675 non-null int64\n",
      "annual_inc                             37675 non-null float64\n",
      "loan_status                            37675 non-null int64\n",
      "dti                                    37675 non-null float64\n",
      "delinq_2yrs                            37675 non-null float64\n",
      "inq_last_6mths                         37675 non-null float64\n",
      "open_acc                               37675 non-null float64\n",
      "pub_rec                                37675 non-null float64\n",
      "revol_bal                              37675 non-null float64\n",
      "revol_util                             37675 non-null float64\n",
      "total_acc                              37675 non-null float64\n",
      "home_ownership_MORTGAGE                37675 non-null int64\n",
      "home_ownership_NONE                    37675 non-null int64\n",
      "home_ownership_OTHER                   37675 non-null int64\n",
      "home_ownership_OWN                     37675 non-null int64\n",
      "home_ownership_RENT                    37675 non-null int64\n",
      "verification_status_Not Verified       37675 non-null int64\n",
      "verification_status_Source Verified    37675 non-null int64\n",
      "verification_status_Verified           37675 non-null int64\n",
      "purpose_car                            37675 non-null int64\n",
      "purpose_credit_card                    37675 non-null int64\n",
      "purpose_debt_consolidation             37675 non-null int64\n",
      "purpose_educational                    37675 non-null int64\n",
      "purpose_home_improvement               37675 non-null int64\n",
      "purpose_house                          37675 non-null int64\n",
      "purpose_major_purchase                 37675 non-null int64\n",
      "purpose_medical                        37675 non-null int64\n",
      "purpose_moving                         37675 non-null int64\n",
      "purpose_other                          37675 non-null int64\n",
      "purpose_renewable_energy               37675 non-null int64\n",
      "purpose_small_business                 37675 non-null int64\n",
      "purpose_vacation                       37675 non-null int64\n",
      "purpose_wedding                        37675 non-null int64\n",
      "term_ 36 months                        37675 non-null int64\n",
      "term_ 60 months                        37675 non-null int64\n",
      "dtypes: float64(12), int64(26)\n",
      "memory usage: 10.9 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loans=pd.read_csv('cleaned_loans_2007.csv')\n",
    "loans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Picking an error metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We established that this is a `binary classification problem` in the first mission of this course, and we converted the loan_status column to 0s and 1s as a result. Before diving in and selecting an algorithm to apply to the data, `we should select an error metric`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective in this is to make money -- we want to fund enough loans that are paid off on time to offset our losses from loans that aren't paid off.` An error metric will help us determine if our algorithm will make us money or lose us money.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An error metric will help us figure out when our model is performing well, and when it's performing poorly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Picking an error metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the number of true negatives.\n",
    "  * Find the number of items where predictions is 0, and the corresponding entry in loans[\"loan_status\"] is also 0.\n",
    "  * Assign the result to tn.\n",
    "* Find the number of true positives.\n",
    "  * Find the number of items where predictions is 1, and the corresponding entry in loans[\"loan_status\"] is also 1.\n",
    "  * Assign the result to tp.\n",
    "* Find the number of false negatives.\n",
    "  * Find the number of items where predictions is 0, and the corresponding entry in loans[\"loan_status\"] is 1.\n",
    "  * Assign the result to fn.\n",
    "* Find the number of false positives.\n",
    "  * Find the number of items where predictions is 1, and the corresponding entry in loans[\"loan_status\"] is 0.\n",
    "  * Assign the result to fp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_renewable_energy</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>10</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment  emp_length  annual_inc  loan_status  \\\n",
       "0     5000.0     10.65       162.87          10     24000.0            1   \n",
       "1     2500.0     15.27        59.83           0     30000.0            0   \n",
       "\n",
       "     dti  delinq_2yrs  inq_last_6mths  open_acc  ...  purpose_major_purchase  \\\n",
       "0  27.65          0.0             1.0       3.0  ...                       0   \n",
       "1   1.00          0.0             5.0       3.0  ...                       0   \n",
       "\n",
       "   purpose_medical  purpose_moving  purpose_other  purpose_renewable_energy  \\\n",
       "0                0               0              0                         0   \n",
       "1                0               0              0                         0   \n",
       "\n",
       "   purpose_small_business  purpose_vacation  purpose_wedding  term_ 36 months  \\\n",
       "0                       0                 0                0                1   \n",
       "1                       0                 0                0                0   \n",
       "\n",
       "   term_ 60 months  \n",
       "0                0  \n",
       "1                1  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for above task\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create train,test sets\n",
    "features=loans.drop(['loan_status'],axis=1)\n",
    "labels=loans['loan_status']\n",
    "train_features,test_features,train_labels,test_labels=train_test_split(features,labels,test_size=0.2,random_state=1)\n",
    "\n",
    "# train model\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "lr=LogisticRegression(solver='lbfgs')\n",
    "lr.fit(train_features,train_labels)\n",
    "\n",
    "# Get predictions for all observations\n",
    "predictions=lr.predict(features)\n",
    "loans['predictions']=predictions\n",
    "loans.predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of true negatives,model predicts loan not paid and actual label is same as model prediction\n",
    "tn=loans.loc[(loans['predictions']==0)&(loans['loan_status']==0),'predictions']\n",
    "tn=len(tn)\n",
    "tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32248"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of true positives,model predicts loan will be paid and actual label is same as model prediction\n",
    "tp=loans.loc[(loans['predictions']==1)&(loans['loan_status']==1),'predictions']\n",
    "tp=len(tp)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of false negatives,model predicts loan not paid but actual label says loan was paid\n",
    "fn=loans.loc[(loans['predictions']==0)&(loans['loan_status']==1),'predictions']\n",
    "fn=len(fn)\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5374"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of false positives,model predicts loan paid but actual label says not paid\n",
    "fp=loans.loc[(loans['predictions']==1)&(loans['loan_status']==0),'predictions']\n",
    "fp=len(fp)\n",
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned earlier that there is a significant class imbalance in the loan_status column. There are 6 times as many loans that were paid off on time (1), than loans that weren't paid off on time (0). `This causes a major issue when we use accuracy as a metric`. `This is because due to the class imbalance, a classifier can predict 1 for every row, and still have high accuracy.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is why it's important to always be `aware of imbalanced classes in machine learning models`, **`and to adjust your error metric accordingly`**. In this case, we don't want to use accuracy, and should instead use metrics that tell us the number of false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This means that we should optimize for**:\n",
    "\n",
    "* `high recall` (true positive rate)\n",
    "* `low fall-out` (false positive rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, `if we want to reduce false positive rate, true positive rate will also go down. This is because if we want to reduce the risk of false positives, we wouldn't think about funding riskier loans in the first place.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "* Compute the false positive rate for predictions.\n",
    "  * Compute the number of false positives, then divide by the number of false positives plus the number of true negatives.\n",
    "  * Assign to fpr.\n",
    "* Compute the true positive rate for predictions.\n",
    "  * Compute the number of true positives, then divide by the number of true positives plus the number of false negatives.\n",
    "  * Assign to tpr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972165522360363"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positive rate, wrongly predicted paid by model divide by total no of actual loan not paid\n",
    "fpr=fp/(fp+tn)\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988230192653162"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true positive rate,correct prediction by model divide by total no of actual loan paid\n",
    "tpr=tp/(tp+fn)\n",
    "tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32250"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "lr=LogisticRegression(solver='lbfgs')\n",
    "predictions=cross_val_predict(lr,features,labels,cv=3)\n",
    "predictionss=pd.Series(predictions)\n",
    "\n",
    "# true positive and false positive\n",
    "tp_filter=(predictionss==1)&(loans['loan_status']==1)\n",
    "tp=len(predictionss[tp_filter])\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5367"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_filter=(predictionss==1)&(loans['loan_status']==0)\n",
    "fp=len(predictionss[fp_filter])\n",
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Penalizing the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, even though we're not using accuracy as an error metric, the classifier is, and it isn't accounting for the imbalance in the classes. There are a few ways to get a classifier to correct for imbalanced classes. The two main ways are:\n",
    "\n",
    "* `Use oversampling and undersampling to ensure that the classifier gets input that has a balanced number of each class.`\n",
    "* `Tell the classifier to penalize misclassifications of the less prevalent class more than the other class.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We'll look into oversampling and undersampling first.` They involve taking a sample that contains equal numbers of rows where loan_status is 0, and where loan_status is 1. This way, the classifier is forced to make actual predictions, since predicting all 1s or all 0s will only result in 50% accuracy at most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downside of this technique is that since it has to preserve an equal ratio, you have to either:\n",
    "\n",
    "* `Throw out many rows of data.` If we wanted equal numbers of rows where loan_status is 0 and where loan_status is 1, one way we could do that is to delete rows where loan_status is 1.\n",
    "* `Copy rows multiple times`. One way to equalize the 0s and 1s is to copy rows where loan_status is 0.\n",
    "* `Generate fake data.` One way to equalize the 0s and 1s is to generate new rows where loan_status is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, none of these techniques are especially easy. The second method we mentioned earlier, telling the classifier to penalize certain rows more, is actually much easier to implement using scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this by setting the `class_weight parameter to balanced when creating the LogisticRegression instance.` This tells scikit-learn to penalize the misclassification of the minority class during the training process. The penalty means that the logistic regression classifier pays more attention to correctly classifying rows where loan_status is 0. This lowers accuracy when loan_status is 1, but raises accuracy when loan_status is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`By setting the class_weight parameter to balanced, the penalty is set to be inversely proportional to the class frequencies.` You can read more about the parameter [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn-linear-model-logisticregression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Penalizing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.567831258130459\n",
      "0.3802189645574318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight=\"balanced\",solver='lbfgs')\n",
    "predictions = cross_val_predict(lr, features, labels, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Manual penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We significantly improved false positive rate in the last screen by balancing the classes, which reduced true positive rate. Our true positive rate is now around 56%, and our false positive rate is around 39%. From a conservative investor's standpoint, it's reassuring that the false positive rate is lower because it means that we'll be able to do a better job at avoiding bad loans than if we funded everything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We can try to lower the false positive rate further by assigning a harsher penalty for misclassifying the negative class. `While setting class_weight to balanced will automatically set a penalty based on the number of 1s and 0s in the column, we can also set a manual penalty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2514712259183547\n",
      "0.09482278715902764\n"
     ]
    }
   ],
   "source": [
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "predictions = cross_val_predict(lr, features, labels, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\krishna\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9700799107972495\n",
      "0.9181666357394693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=1)\n",
    "predictions = cross_val_predict(rf, features, labels ,cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.`\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given this, there's still quite a bit of room to improve:**\n",
    "\n",
    "* We can tweak the penalties further.\n",
    "* We can try models other than a random forest and logistic regression.\n",
    "* We can use some of the columns we discarded to generate better features.\n",
    "* We can `ensemble multiple models` to get more accurate predictions.\n",
    "* We can `tune the parameters of the algorithm` to achieve higher performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
