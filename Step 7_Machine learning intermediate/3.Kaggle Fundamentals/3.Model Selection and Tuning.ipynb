{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducing Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the previous mission, `we worked to optimize our predictions by creating and selecting the features used to train our model.` The other half of the optimization puzzle is to `optimize the model itself— or more specifically, the algorithm used to train our model.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are hundreds of different machine learning algorithms from which we can choose. Each algorithm has different strengths and weaknesses, and so we need to select the algorithm that works best with our specific data— in this case our Kaggle competition.\n",
    "\n",
    "**`The process of selecting the algorithm which gives the best predictions for your data is called model selection.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To save time, we have saved the features we created in the previous mission as CSV files, `train_modified.csv` and `holdout_modified.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Import train_modified.csv into a pandas dataframe and assign the result to train.\n",
    "* Import holdout_modified.csv into a pandas dataframe and assign the result to holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train=pd.read_csv('train_modified.csv')\n",
    "holdout=pd.read_csv('holdout_modified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training a Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Instantiate a linear_model.LogisticRegression class.\n",
    "* Use the model_selection.cross_val_score() function to train and test a model assigning the result to scores, using:\n",
    "* The LogisticRegression object you just created.\n",
    "   * all_X and all_y as the X and y parameters\n",
    "   * 10 folds.\n",
    "* Calculate the mean of scores and assign the result to accuracy_lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8250025536261492"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "all_x = train.drop(['Survived','PassengerId'],axis=1)\n",
    "all_y = train['Survived']\n",
    "\n",
    "lr=LogisticRegression(solver='lbfgs')\n",
    "scores=cross_val_score(lr,all_x,all_y,cv=10)\n",
    "\n",
    "accuracy_lr=scores.mean()\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training a Model using K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`The k-nearest neighbors algorithm` finds the observations in our training set most similar to the observation in our test set, and uses the average outcome of those 'neighbor' observations to make a prediction. The 'k' is the number of neighbor observations used to make the prediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Instantiate a neighbors.KNeighborsClassifier object, setting the n_neighbors argument to 1.\n",
    "* Use the model_selection.cross_val_score() function to train and test a model assigning the result to scores, using:\n",
    "* The KNeighborsClassifier object you just created.\n",
    "  * all_X and all_y as the the X and y parameters.\n",
    "  * 10 folds.\n",
    "* Calculate the mean of scores and assign the result to accuracy_knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857382816933379"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "scores=cross_val_score(knn,all_x,all_y,cv=10)\n",
    "accuracy_knn=scores.mean()\n",
    "accuracy_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploring Different K Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Besides pure model selection, we can vary the settings of each model— for instance the value of k in our k-nearest neighbors model. This is called **`hyperparameter optimization`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use a loop and Python's inbuilt range() class to iterate through different values for k and calculate the accuracy score for each different value. We will only want to test odd values for k to avoid ties, where both 'survived' and 'died' outcomes would have the same number of neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Use a for loop and the range class to iterate over odd values of k from 1-49, and in each iteration:\n",
    "  * Instantiate a KNeighborsClassifier object with the value of k for the n_neighbors argument.\n",
    "  * Use cross_val_score to create a list of scores using the newly created KNeighborsClassifier object, using all_X, all_y, and    cv=10 as the arguments.\n",
    "  * Calculate the mean of the list of scores.\n",
    "  * Add the mean of the scores to the dictionary knn_scores, using k for the key.\n",
    "* Use the plot_dict() helper function to plot the knn_scores dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "def plot_dict(dictionary):\n",
    "    pd.Series(dictionary).plot.bar(figsize=(9,6),ylim=(0.78,0.83),rot=0)\n",
    "    print(pd.Series(dictionary))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores={}\n",
    "for k in range(1,50,2):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    scores=cross_val_score(knn,all_x,all_y,cv=10)\n",
    "    knn_scores[k]=scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     0.785738\n",
      "3     0.804841\n",
      "5     0.822718\n",
      "7     0.820459\n",
      "9     0.821582\n",
      "11    0.811507\n",
      "13    0.817125\n",
      "15    0.811494\n",
      "17    0.814940\n",
      "19    0.823891\n",
      "21    0.817099\n",
      "23    0.819334\n",
      "25    0.815963\n",
      "27    0.810358\n",
      "29    0.800245\n",
      "31    0.803629\n",
      "33    0.804727\n",
      "35    0.797960\n",
      "37    0.793515\n",
      "39    0.794665\n",
      "41    0.792430\n",
      "43    0.798048\n",
      "45    0.796899\n",
      "47    0.794664\n",
      "49    0.784601\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dict(knn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Automating Hyperparameter Optimization with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Model\t|Cross-validation score|\tKaggle score|\n",
    "|-------|----------------------|----------------|\n",
    "|Previous best Kaggle score|\t82.3%|\t78.0%|\n",
    "|Logistic regression baseline|\t82.4%|\t|\n",
    "|K-nearest neighbors, k == 1|\t78.6%||\t\n",
    "|K-nearest neighbors,k == 19|\t82.4%||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The technique we just used is called `grid search - we train a number of models across a 'grid' of values and then searched for the model that gave us the highest accuracy`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scikit-learn has a class to perform grid search, model_selection.GridSearchCV(). The 'CV' in the name indicates that we're `performing both grid search and cross validation at the same time.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our final step is to print the `GridSearchCV.best_params_` and `GridSearchCV.best_score_` attributes to retrieve the parameters of the best-performing model, and the score it achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Instantiate a KNeighborsClassifier object.\n",
    "* Instantiate a GridSearchCV object, using:\n",
    "  * The KNeighborsClassifier object you just created as the first (unnamed) argument.\n",
    "  * The hyperparameters dictionary for the param_grid.\n",
    "  * A cv of 10.\n",
    "* Fit the GridSearchCV object using all_X and all_y.\n",
    "* Assign the parameters of the best performing model to best_params.\n",
    "* Assign the score of the best performing model to best_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282828282828283"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "hyperparameters = {\n",
    "    \"n_neighbors\": range(1,20,2),\n",
    "    \"weights\": [\"distance\", \"uniform\"],\n",
    "    \"algorithm\": ['brute'],\n",
    "    \"p\": [1,2]\n",
    "}\n",
    "knn=KNeighborsClassifier()\n",
    "grid=GridSearchCV(knn,param_grid=hyperparameters,cv=10)\n",
    "grid.fit(all_x,all_y)\n",
    "best_params=grid.best_params_\n",
    "best_score=grid.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'brute', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Submitting K-Nearest Neighbors Predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use the GridSearchCV.best_estimator_ attribute to retrieve a trained model with the best-performing hyperparameters. This code:\n",
    "\n",
    "`best_knn = grid.best_estimator_`\n",
    "\n",
    "is equivalent to this code where we manually specify the hyperparameters and train the model:\n",
    "\n",
    "`best_knn = KNeighborsClassifier(p=1,algorithm='brute',n_neighbors=5,\n",
    "                     weights='uniform')\n",
    "best_knn.fit(all_X,all_y)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Make predictions on the data from holdout_no_id using the best_knn model, and assign the result to holdout_predictions.\n",
    "* Create a dataframe submission with two columns:\n",
    "  * PassengerId, with the values from the PassengerId column of the holdout dataframe.\n",
    "  * Survived, with the values from holdout_predictions.\n",
    "* Use the DataFrame.to_csv method to save the submission dataframe to the filename submission_1.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_no_id=holdout.drop(['PassengerId'],axis=1)\n",
    "best_knn=grid.best_estimator_\n",
    "holdout_predictions=best_knn.predict(hold_no_id)\n",
    "submission=pd.DataFrame({'PassengerId':holdout['PassengerId'],'Survived':holdout_predictions})\n",
    "submission.to_csv('submission_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Introducing Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random forests is a specific type of decision tree algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decision tree algorithms attempt to build the most efficient decision tree based on the training data, and then use that tree to make future predictions.\n",
    "* Scikit-learn contains a class for classification using the random forest algorithm, `ensemble.RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Instantiate a RandomForestClassifier object, setting the random_state parameter to 1.\n",
    "* Use the cross_val_score() function to generate a set of scores and assign the result to scores, using:\n",
    "  * The RandomForestClassifier object you just created as the estimator\n",
    "  * all_X and all_y for the train and test data\n",
    "  * A cv value of 10\n",
    "* Calculate the mean of scores and assign the result to accuracy_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846013505844966"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(random_state=1)\n",
    "scors=cross_val_score(rfc,all_x,all_y,cv=10)\n",
    "accuracy_rf=scores.mean()\n",
    "accuracy_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Tuning our Random Forests Model with GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Instantiate a RandomForestClassifier object, setting the random_state parameter to 1.\n",
    "* Instantiate a GridSearchCV object, using:\n",
    "  * The RandomForestClassifier object you just created as the first (unnamed) argument.\n",
    "  * A dictionary of hyperparameters that matches the list above for the param_grid argument\n",
    "  * A cv of 10.\n",
    "  * Fit the GridSearchCV object using all_X or all_y.\n",
    "* Assign the parameters of the best performing model to best_params\n",
    "* Assign the score of the best performing model to best_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428731762065096"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\"criterion\": [\"entropy\", \"gini\"],\n",
    "                   \"max_depth\": [5, 10],\n",
    "                   \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": [1, 5],\n",
    "                   \"min_samples_split\": [3, 5],\n",
    "                   \"n_estimators\": [6, 9]}\n",
    "\n",
    "clf=RandomForestClassifier(random_state=1)\n",
    "grid=GridSearchCV(clf,param_grid=hyperparameters,cv=10)\n",
    "grid.fit(all_x,all_y)\n",
    "best_params=grid.best_params_\n",
    "best_score=grid.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Submitting Random Forest Predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Assign the best performing model from the GridSearchCV object grid to best_rf.\n",
    "* Make predictions on the data from holdout_no_id using the best_rf model, and assign the result to holdout_predictions.\n",
    "* Create a dataframe submission with two columns:\n",
    "  * PassengerId, with the values from the PassengerId column of the holdout dataframe.\n",
    "  * Survived, with the values from holdout_predictions.\n",
    "* Use the DataFrame.to_csv method to save the submission dataframe to the filename submission_2.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_predictions=best_rf.predict(hold_no_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame({'PassengerId':holdout['PassengerId'],'Survived':holdout_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved score summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Model|\tCross-validation score\t|Kaggle score|\n",
    "|--------------------------|----------|-------|\n",
    "|Previous best Kaggle score|\t82.3%|\t78.0%|\n",
    "|Logistic regression baseline|\t82.4%|\t-|\n",
    "|K-nearest neighbors, k == 1\t|78.6%|- |\t\n",
    "|K-nearest neighbors, k == 19|\t82.4%\t|-|\n",
    "|K-nearest neighbors, best model from grid search|\t82.8%\t|75.6%|\n",
    "|Random forests, default hyperparameters|\t80.7%\t|-|\n",
    "|Random forests, best model from grid search|\t84.3%|\t77.1%|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
