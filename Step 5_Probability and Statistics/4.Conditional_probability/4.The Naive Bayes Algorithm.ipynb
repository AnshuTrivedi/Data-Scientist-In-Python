{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the last three missions, we've managed to learn many new concepts, including conditional probability, independence, the law of total probability, and Bayes' theorem. In this mission and the next, we'll look at an application of conditional probability — we'll build a spam filter.\n",
    "\n",
    "Spam is most commonly associated with emails. For instance, unwanted and unsolicited advertising emails are usually classified as spam. Spamming, however, occurs in ways and environments that don't necessarily relate to emails:\n",
    "\n",
    "* Articles or blog posts can be spammed with comments — the comments are ads or they are repetitive.\n",
    "* An educational forum may be spammed with posts that are, in fact, ads.\n",
    "* Mobile phone users may receive unwanted and unsolicited SMS messages, usually about advertising.\n",
    "\n",
    "To build the spam filter, we're going to use an algorithm called Naive Bayes — as the name suggests, the algorithm is based on Bayes' theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive Bayes Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we just got a new SMS message:\n",
    "\n",
    "\"WINNER! You have 8 hours to claim your money by calling 090061701461. Claim code: KL341.\"\n",
    "This must be spam, but how could we create an algorithm that reaches the same conclusion? One thing we might think of is to create a list of words that occurr frequently in spam messages, and then write a bunch of if statements:\n",
    "\n",
    "If the word \"money\" is in the message, then classify the message as spam.\n",
    "If the words \"secret\" and \"money\" are both in the message, then classify the message as spam; etc.\n",
    "However, as messages become numerous and more complex, coming up with the right if statements will slowly become very difficult.\n",
    "\n",
    "Another solution would be to classify a couple of messages ourselves and make the computer learn from our classification. And this is exactly what the Naive Bayes algorithm is about: It makes the computer learn from the classification a humans does, and then the computer uses that knowledge to classify new messages.\n",
    "\n",
    "The computer uses the specifications of the Naive Bayes algorithm to learn how we classify messages (what counts as spam and non-spam for us), and then it uses that human knowledge to estimate probabilities for new messages. Following the specifications of the algorithm, the computer tries to answer two conditional probability questions:\n",
    "\n",
    "$\\begin{equation}\n",
    "P(Spam | New\\ message) =\\ ? \\\\\n",
    "P(Spam^C |New\\ message) =\\ ?\n",
    "\\end{equation}$\n",
    "\n",
    "In plain English, these two questions are:\n",
    "\n",
    "* What's the probability that this new message is spam, given its content (its words, punctuation, letter case, etc.)?\n",
    "* What's the probability that this new message is non-spam, given its content?\n",
    "\n",
    "Once it has an answer to these two questions, the computer classifies the message as spam or non-spam based on the probability values. If the probability for spam is greater, then the message is classified as spam. Otherwise, it goes into the non-spam category.\n",
    "\n",
    "Now let's move to the next screen, where we'll start to look into the details of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the previous screen, we saw an overview of how the computer may classify new messages using the Naive Bayes algorithm:\n",
    "\n",
    "* The computer learns how humans classify messages.\n",
    "* Then it uses that human knowledge to estimate probabilities for new messages — probabilities for spam and non-spam.\n",
    "* Finally, the computer classifies a new message based on the probability values it calculated in step 2 — if the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, then we may want a human to classify the message — we'll come back to this issue in the guided project)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | New\\ message) =\\ ? \\\\\n",
    "P(Spam^C |New\\ message) =\\ ?\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the first equation and expand it using Bayes' theorem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\begin{equation}\n",
    "P(Spam | New\\ message) = \\frac{P(Spam) \\cdot P(New\\ Message | Spam)}{P(New\\ message)}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same for the second equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\begin{equation}\n",
    "P(Spam^C | New\\ message) = \\frac{P(Spam^C) \\cdot P(New\\ Message | Spam^C)}{P(New\\ message)}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of example, let's assume the following probabilities are already known:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "&P(Spam) = 0.5 \\\\\n",
    "&P(Spam^C) = 0.5 \\\\\n",
    "&P(New\\ message) = 0.4167 \\\\\n",
    "&P(New\\ Message | Spam) = 0.5 \\\\\n",
    "&P(New\\ Message | Spam^C) = 0.3334\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = 0.5\n",
    "p_non_spam = 0.5\n",
    "p_new_message = 0.5417\n",
    "p_new_message_given_spam = 0.75\n",
    "p_new_message_given_non_spam = 0.3334\n",
    "p_spam_given_new_message = (p_spam * p_new_message_given_spam) / p_new_message\n",
    "p_non_spam_given_new_message = (p_non_spam * p_new_message_given_non_spam) / p_new_message\n",
    "\n",
    "classification = 'spam' # p_spam_given_new_message > p_non_spam_given_new_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ignoring the Division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the last screen, we saw the computer can use these two equations to calculate the probabilities it needs to classify new messages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | New\\ message) = \\frac{P(Spam) \\cdot P(New\\ Message | Spam)}{P(New\\ message)} \\\\\n",
    "P(Spam^C | New\\ message) = \\frac{P(Spam^C) \\cdot P(New\\ Message | Spam^C)}{P(New\\ message)}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we've taken a great first step so far, the actual equations of the Naive Bayes algorithm are a bit different — we'll gradually develop the equations throughout this mission. Let's start by pointing out that both equations above have the same denominator: P(New message).\n",
    "\n",
    "When a new message comes in, P(New message) has the same value for both equations. Since we only need to compare the results of the two equations to classify a new message, we can ignore the division:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "\\frac{P(Spam) \\cdot P(New\\ Message | Spam)}{P(New\\ message)}\\ \\ \\ \\  \\xrightarrow[]{becomes}\\ \\ \\ \\  P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "\\frac{P(Spam^C) \\cdot P(New\\ Message | Spam^C)}{P(New\\ message)}\\ \\ \\  \\xrightarrow[]{becomes}\\ \\ \\ \\  P(Spam^C) \\cdot P(New\\ Message | Spam^C)\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means our two equations reduce to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | New\\ message) = P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "P(Spam^C | New\\ message) = P(Spam^C) \\cdot P(New\\ Message | Spam^C)\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring the division doesn't affect the algorithm's ability to classify new messages. For instance, let's repeat the classification we did on the previous screen using the new equations above. Recall that we assumed we already know these values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "&P(Spam) = 0.5 \\\\\n",
    "&P(Spam^C) = 0.5 \\\\\n",
    "&P(New\\ message) = 0.4167 \\\\\n",
    "&P(New\\ Message | Spam) = 0.5 \\\\\n",
    "&P(New\\ Message | Spam^C) = 0.3334\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, the algorithm classified the new message as spam. Using the new equations, we see the conclusion is identical — the new message is spam because"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "P(Spam | New\\ message) &= P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "&= 0.5 \\cdot 0.5 = 0.25\n",
    "\\end{aligned}$\n",
    "\n",
    "$\\begin{aligned}\n",
    "P(Spam^C | New\\ message) &= P(Spam^C) \\cdot P(New\\ Message | Spam^C) \\\\\n",
    "&= 0.5 \\cdot 0.3334 = 0.1667\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification works fine, but ignoring the division changes the probability values, and some probability rules also begin to break. For instance, let's take this conditional probability rule that we've learned about in a previous mission:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(A|B) + P(A^C|B) = 1\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the previous screen, we saw $P(Spam | New\\ message) = 0.6$ and $P(Spam^C | New\\ message) = 0.4$, and the rule holds with these values:\n",
    "$\\begin{equation}\n",
    "P(Spam | New\\ message) + P(Spam^C | New\\ message) = 0.6 + 0.4 = 1\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the values we got from the new equations, however, the law breaks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | New\\ message) + P(Spam^C | New\\ message) = 0.25 + 0.1667 = 0.4167 \\not = 1\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Even though probability rules break, the Naive Bayes algorithm still requires us to ignore the division by P(New message). This might not make a lot of sense, but there's actually a very good reason we do that.`\n",
    "\n",
    "`The main goal of the algorithm is to classify new messages, not to calculate probabilities — calculating probabilities is just a means to an end. Ignoring the division by P(New message) means less calculations, which can make a lot of difference when we use the algorithm to classify 500,000 new messages.`\n",
    "\n",
    "`It's true the probability values are not accurate anymore. However, this is not important with respect to the the goal of the algorithm — correctly classifying new messages (not to accurately estimate probabilities).`\n",
    "\n",
    "`The classification itself remains completely unaffected because we ignore division for both equations (not just for one). The probability values change, but they change directly proportional with one another, so the result of the comparison doesn't change.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "A new mobile message has been received: \"URGENT!! You have one day left to claim your `$873` prize.\" The following probabilities are known:\n",
    "\n",
    "$\\begin{aligned}\n",
    "&P(Spam) = 0.5 \\\\\n",
    "&P(Spam^C) = 0.5 \\\\\n",
    "&P(New\\ Message | Spam) = 0.75 \\\\\n",
    "&P(New\\ Message | Spam^C) = 0.3334\n",
    "\\end{aligned}$\n",
    "\n",
    "Use the new equations we learned on this screen, and classify the new message as spam or non-spam:\n",
    "\n",
    "* Calculate P(Spam|New Message). Assign your answer to p_spam_given_new_message.\n",
    "* Calculate P(SpamC|New Message). Assign your answer to p_non_spam_given_new_message.\n",
    "* Classify the message by comparing the probability values — if the message is spam, then assign the string 'spam' to the variable classification. Otherwise, assign the string 'non-spam'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = 0.5\n",
    "p_non_spam = 0.5\n",
    "p_new_message_given_spam = 0.75\n",
    "p_new_message_given_non_spam = 0.3334\n",
    "p_spam_given_new_message = p_spam * p_new_message_given_spam\n",
    "p_non_spam_given_new_message = p_non_spam * p_new_message_given_non_spam\n",
    "\n",
    "classification = 'spam' # p_spam_given_new_message > p_non_spam_given_new_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. A One-Word Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the previous screen, we optimized the algorithm and concluded that we can use these two optimized equations if all we're interested in is classifying messages (and not calculating accurate probabilities):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | New\\ message) \\propto P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "P(Spam^C | New\\ message) \\propto P(Spam^C) \\cdot P(New\\ Message | Spam^C)\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say the one-word message \"secret\" comes in and we want to use the Naive Bayes algorithm to classify it — to tell whether it's spam or non-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned, we first need to answer these two probability questions (note that we changed New Message to \"secret\" inside the notation below) and then compare the values (recall that the  symbol replaces the equal sign):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | \\text{\"secret\"}) \\propto P(Spam) \\cdot P(\\text{\"secret\"} | Spam) \\\\\n",
    "P(Spam^C | \\text{\"secret\"}) \\propto P(Spam^C) \\cdot P(\\text{\"secret\"} | Spam^C)\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "Using the table below (there are the same messages as above), classify the message \"secret\" as spam or non-spam.\n",
    "\n",
    "|Label|SMS|\n",
    "|----|----|\n",
    "|spam|secret money secret secret|\n",
    "|spam|money secret place|\n",
    "|non-spam|you know the secret|\n",
    "|?|secret|\n",
    "\n",
    "* Calculate P(SpamC) and assign the answer to p_non_spam.\n",
    "* Calculate P(\"secret\"|SpamC) and assign the answer to p_secret_given_non_spam.\n",
    "* Calculate P(SpamC|\"secret\") and assign the answer to p_non_spam_given_secret.\n",
    "* Compare P(SpamC|\"secret\") with P(Spam|\"secret\") and classify the message \"secret\" — if the message is spam, then assign the string 'spam' to the variable classification, otherwise assign the string 'non-spam'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam_given_secret = 8/21\n",
    "p_non_spam = 1/3\n",
    "p_secret_given_non_spam = 1/4\n",
    "p_non_spam_given_secret = p_non_spam * p_secret_given_non_spam\n",
    "classification = 'spam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Multiple Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the previous screen, we used our algorithm to classify the message \"secret\", and we concluded it's spam. The message \"secret\" has only one word, but what about the situation where we have to classify messages that have more words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Label|SMS|\n",
    "|----|----|\n",
    "|non-spam|secret party at my place|\n",
    "|spam|secret money secret secret|\n",
    "|spam|money secret place|\n",
    "|non-spam|you know the secret|\n",
    "|?|secret place secret secret|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the probabilities we need, we'll treat each word in our new message separately. This means that the word \"secrete\" at the beginning is different and separate from the word \"secret\" at the end. There are four words in the message \"secret place secret secret\", and we're going to abbreviate them \"w1\", \"w2\", \"w3\" and \"w4\" (the \"w\" comes from \"word\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2,w_3,w_4) \\propto P(Spam) \\cdot P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot P(w_3|Spam) \\cdot P(w_4|Spam) \\\\\n",
    "P(Spam^C | w_1,w_2,w_3,w_4) \\propto P(Spam^C) \\cdot P(w_1|Spam^C) \\cdot P(w_2|Spam^C) \\cdot P(w_3|Spam^C) \\cdot P(w_4|Spam^C) \\\\\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with calculating P(Spam|w1, w2, w3, w4). To calculate the probabilities we need, we'll look at the four messages that are already classified. We have four messages and two of them are spam, so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam) = \\frac{2}{4} = \\frac{1}{2}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first word, w1, is \"secret\", and we see that \"secret\" occurs four times in all spam messages. There's a total of seven words in all the spam messages, so:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(w_1|Spam) = \\frac{4}{7} \n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a similar reasoning, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(w_2|Spam) = \\frac{1}{7} \\\\\n",
    "P(w_3|Spam) = \\frac{4}{7} \\\\\n",
    "P(w_4|Spam) = \\frac{4}{7}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the probabilities we need to calculate P(Spam|w1, w2, w3, w4):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "P(Spam | w_1,w_2,w_3,w_4) &\\propto P(Spam) \\cdot P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot P(w_3|Spam) \\cdot P(w_4|Spam) \\\\\n",
    "&= \\frac{1}{2} \\cdot \\frac{4}{7} \\cdot \\frac{1}{7} \\cdot \\frac{4}{7} \\cdot \\frac{4}{7} = \\frac{64}{4802} = 0.01333\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "Using the table below (the same as above), classify the message \"secret place secret secret\" as spam or non-spam.\n",
    "\n",
    "|Label|SMS|\n",
    "|----|----|\n",
    "|non-spam|secret party at my place|\n",
    "|spam|secret money secret secret|\n",
    "|spam|money secret place|\n",
    "|non-spam|you know the secret|\n",
    "|?|secret place secret secret|\n",
    "\n",
    "* Calculate P(SpamC|w1, w2, w3, w4). Assign the answer to p_non_spam_given_w1_w2_w3_w4. Check the hint if you get stuck.\n",
    "* Compare P(SpamC|w1, w2, w3, w4) with P(Spam|w1, w2, w3, w4) and classify the message \"secret place secret secret\" — if the message is spam, then assign the string 'spam' to the variable classification. Otherwise, assign the string 'non-spam'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam_given_w1_w2_w3_w4 = 64/4802\n",
    "p_non_spam = 2/4\n",
    "p_w1_given_non_spam = 2/9\n",
    "p_w2_given_non_spam = 1/9\n",
    "p_w3_given_non_spam = 2/9\n",
    "p_w4_given_non_spam = 2/9\n",
    "\n",
    "p_non_spam_given_w1_w2_w3_w4 = (p_non_spam *\n",
    "                                p_w1_given_non_spam * p_w2_given_non_spam *\n",
    "                                p_w3_given_non_spam * p_w4_given_non_spam\n",
    "                               )\n",
    "\n",
    "classification = 'spam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conditional Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we introduced these two equations without much explanation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2,w_3,w_4) \\propto P(Spam) \\cdot P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot P(w_3|Spam) \\cdot P(w_4|Spam) \\\\\n",
    "P(Spam^C | w_1,w_2,w_3,w_4) \\propto P(Spam^C) \\cdot P(w_1|Spam^C) \\cdot P(w_2|Spam^C) \\cdot P(w_3|Spam^C) \\cdot P(w_4|Spam^C) \\\\\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain the mathematics behind these equations, let's start by looking at P(Spam|w1, w2, w3, w4). Using the conditional probability formula, we can expand P(Spam|w1, w2, w3, w4) like this (below, make sure you notice the $\\cap$ symbol in the numerator):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2,w_3,w_4) = \\frac{P(Spam \\cap (w_1, w_2, w_3, w_4))}{P(w_1, w_2, w_3, w_4)}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we learned in a previous screen that we can ignore the division, which means we can drop P(w1, w2, w3, w4) to avoid redundant calculations (when we ignore the division, we also replace the equals sign with , which means directly proportional):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2,w_3,w_4) \\propto P(Spam \\cap (w_1, w_2, w_3, w_4))\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that (w1, w2, w3, w4) can be modeled as an intersection of four events:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "w_1,w_2,w_3,w_4 = w_1 \\cap w_2 \\cap w_3 \\cap w_4\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we could think of a message like \"thanks for your help\" as the intersection of four words inside a single message: \"thanks\", \"for, \"your\", and \"help\". In probability jargon, finding the value of $P(w_1 \\cap w_2 \\cap w_3 \\cap w_4)$ means finding the probability that the four words w1, w2, w3, w4 occur together in a single message — this is similar to $P(A \\cap B \\cap C \\cap D)$, which is the probability that events A, B, C, and D occur together.\n",
    "\n",
    "With this in mind, our equation above transforms to:\n",
    "\n",
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2,w_3,w_4) \\propto P(Spam \\cap \\underbrace{(w_1 \\cap w_2 \\cap w_3 \\cap w_4)}_{\\displaystyle (w_1,w_2,w_3,w_4)})\n",
    "\\end{equation}$\n",
    "\n",
    "\n",
    "From set theory, we know that $A \\cap (B \\cap C) = A \\cap B \\cap C = C \\cap B \\cap A$, which means we can transform $P(Spam \\cap (w_1 \\cap w_2 \\cap w_3 \\cap w_4))$ in our equation above to make it suitable for further expansion:\n",
    "\n",
    "$\\begin{aligned}\n",
    "P(Spam \\cap (w_1 \\cap w_2 \\cap w_3 \\cap w_4)) &= P(Spam \\cap w_1 \\cap w_2 \\cap w_3 \\cap w_4) \\\\\n",
    "&= P(w_1 \\cap w_2 \\cap w_3 \\cap w_4 \\cap Spam)\n",
    "\\end{aligned}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the multiplication rule to expand $P(w_1 \\cap w_2 \\cap w_3 \\cap w_4 \\cap Spam)$:\n",
    "\n",
    "$\\begin{equation}\n",
    "P(w_1 \\cap w_2 \\cap w_3 \\cap w_4 \\cap Spam) = P(w_1 | w_2 \\cap w_3 \\cap w_4 \\cap Spam) \\cdot P(w_2 \\cap w_3 \\cap w_4 \\cap Spam)\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the multiplication rule again to expand P(w2 ∩ w3 ∩ w4 ∩ Spam):\n",
    "$\\begin{equation}\n",
    "P(w_1 \\cap w_2 \\cap w_3 \\cap w_4 \\cap Spam) = P(w_1 | w_2 \\cap w_3 \\cap w_4 \\cap Spam) \\cdot \\underbrace{P(w_2 | w_3 \\cap w_4 \\cap Spam) \\cdot P(w_3 \\cap w_4 \\cap Spam)}_{\\displaystyle P(w_2 \\cap w_3 \\cap w_4 \\cap Spam)}\n",
    "\\end{equation}$\n",
    "\n",
    "We can use the multiplication rule successively, until there's nothing more left to expand:\n",
    "\n",
    "$\\begin{aligned}\n",
    "P(w_1 \\cap w_2 \\cap w_3 \\cap w_4 \\cap Spam) &= P(w_1 | w_2 \\cap w_3 \\cap w_4 \\cap Spam) \\cdot P(w_2 \\cap w_3 \\cap w_4 \\cap Spam) \\\\\n",
    "&= P(w_1 | w_2 \\cap w_3 \\cap w_4 \\cap Spam) \\cdot P(w_2 | w_3 \\cap w_4 \\cap Spam) \\cdot P(w_3 \\cap w_4 \\cap Spam) \\\\\n",
    "&= P(w_1 | w_2 \\cap w_3 \\cap w_4 \\cap Spam) \\cdot P(w_2 | w_3 \\cap w_4 \\cap Spam) \\cdot P(w_3 | w_4 \\cap Spam) \\cdot P(w_4 \\cap Spam) \\\\\n",
    "&= P(w_1 | w_2 \\cap w_3 \\cap w_4 \\cap Spam) \\cdot P(w_2 | w_3 \\cap w_4 \\cap Spam) \\cdot P(w_3 | w_4 \\cap Spam) \\cdot P(w_4|Spam) \\cdot P(Spam) \\\\\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory, the last equation you see above is what we'd have to use if we wanted to calculate P(Spam|w1, w2, w3, w4). However, the equation is pretty long for just four words. Also, imagine how would the equation look for a 50-word message — just think of how many calculations we'd have to perform!!\n",
    "\n",
    "To make the calculations tractable for messages of all kinds of lengths, we can assume conditional independence between w1, w2, w3, and w4. This implies that:\n",
    "\n",
    "$\\begin{aligned}\n",
    "&P(w_1 | w_2 \\cap w_3 \\cap w_4 \\cap Spam) = P(w_1|Spam) \\\\\n",
    "&P(w_2 | w_3 \\cap w_4 \\cap Spam) = P(w_2|Spam) \\\\ \n",
    "&P(w_3 | w_4 \\cap Spam) = P(w_3|Spam) \\\\\n",
    "&P(w_4|Spam) = P(w_4|Spam) \\\\\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Under the assumption of independence, our lengthy equation above reduces to:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(w_1 \\cap w_2 \\cap w_3 \\cap w_4 \\cap Spam) = P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot P(w_3|Spam) \\cdot P(w_4|Spam) \\cdot P(Spam)\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assumption of conditional independence is unrealistic in practice because words are often in a relationship of dependence. For instance, if you see the word \"WINNER\" in a message, the probability of seeing the word \"money\" is very likely to increase, so \"WINNER\" and \"money\" are most likely dependent. The assumption of conditional independence between words is thus naive since it rarely holds in practice, and this is why the algorithm is called Naive Bayes (also called simple Bayes or independence Bayes).\n",
    "\n",
    "Despite this simplifying assumption, the algorithm works quite well in many real-word situations, and we'll see that ourselves in the guided project.\n",
    "\n",
    "That being said, on the previous screen we assumed conditional independence when we introduced these two equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2,w_3,w_4) \\propto P(Spam) \\cdot P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot P(w_3|Spam) \\cdot P(w_4|Spam) \\\\\n",
    "P(Spam^C | w_1,w_2,w_3,w_4) \\propto P(Spam^C) \\cdot P(w_1|Spam^C) \\cdot P(w_2|Spam^C) \\cdot P(w_3|Spam^C) \\cdot P(w_4|Spam^C) \\\\\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 8. A General Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equations above work for messages that have four words, but we need a more general form to use with messages of various word lengths.\n",
    "\n",
    "A new message has n words, where n can be any positive integer (1, 2, 3, ..., 50, 51, 53, ...). If we wanted to find P(Spam|w1, w2, ..., wn), then this is an equation we could use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2, \\ldots, w_n) \\propto P(Spam) \\cdot P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot \\ldots \\cdot P(w_n|Spam)\n",
    "\\end{equation}$\n",
    "\n",
    "Notice that there's a certain pattern in the equation above — after P(Spam), the only thing that changes is the word number.\n",
    "\n",
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2, \\ldots, w_n) \\propto P(Spam) \\cdot P(\\overbrace{w_1}^{1}|Spam) \\cdot P(\\overbrace{w_2}^{2}|Spam) \\cdot \\ldots \\cdot P(\\overbrace{w_n}^{n}|Spam)\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we have a product that follows a pattern like that, it's common to use the $\\prod$ symbol (this is the uppercase Greek letter \"pi\"). So the equation above simplifies to:\n",
    "\n",
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2, \\ldots, w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}$\n",
    "\n",
    "The equation above is the same as:\n",
    "\n",
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2, \\ldots, w_n) \\propto P(Spam) \\cdot \\overbrace{P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot \\ldots \\cdot P(w_n|Spam)}^{\\displaystyle \\prod_{i=1}^{n}P(w_i|Spam)}\n",
    "\\end{equation}$\n",
    "\n",
    "Applying the same reasoning to P(SpamC|w1, w2, ..., wn), we have:\n",
    "\n",
    "# $\\begin{equation}\n",
    "P(Spam^C | w_1,w_2, \\ldots, w_n) \\propto P(Spam^C) \\cdot \\prod_{i=1}^{n}P(w_i|Spam^C)\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Edge Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have four messages and nine unique words: \"secret\", \"party\", \"at\", \"my\", \"place\", \"money\", \"you\", \"know\", \"the\". We call the set of unique words a vocabulary.\n",
    "\n",
    "Now, what if we receive a new message that contains words which are not part of the vocabulary? How do we calculate probabilities for this kind of words?\n",
    "\n",
    "Notice that for this new message:\n",
    "\n",
    "* The words \"code\", \"to\", and \"unlock\" are not part of the vocabulary.\n",
    "* The word \"secret\" is part of both spam and non-spam messages.\n",
    "* The word \"money\" is only part of the spam messages and is missing from the non-spam messages.\n",
    "* The word \"the\" is missing from the spam messages and is only part of the non-spam messages.\n",
    "\n",
    "Whenever we have to deal with words that are not part of the vocabulary, one solution is to ignore them when we're calculating probabilities. If we wanted to calculate P(Spam|\"secret code to unlock the money\"), we could skip calculating P(\"code\"|Spam), P(\"to\"|Spam), and P(\"unlock\"|Spam) because \"code\", \"to\", and \"unlock\" are not part of the vocabulary:\n",
    "\n",
    "$\\begin{equation}\n",
    "P(Spam|\\text{\"secret code to unlock the money\"}) \\propto P(Spam) \\cdot {P(\\text{\"secret\"}|Spam) \\cdot P(\\text{\"the\"}|Spam) \\cdot P(\\text{\"money\"}|Spam)}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply the same reasoning for calculating P(SpamC|\"secret code to unlock the money\"):\n",
    "\n",
    "$\\begin{equation}\n",
    "P(Spam^C|\\text{\"secret code to unlock the money\"}) \\propto P(Spam^C) \\cdot P(\\text{\"secret\"}|Spam^C) \\cdot P(\\text{\"the\"}|Spam^C) \\cdot P(\\text{\"money\"}|Spam^C)\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "P(Spam|\"secret code to unlock the money\") is already calculated for you. Use the table below (the same as above) to calculate P(SpamC|\"secret code to unlock the money\").\n",
    "\n",
    "|Label|SMS|\n",
    "|----|----|\n",
    "|non-spam|secret party at my place|\n",
    "|spam|secret money secret secret|\n",
    "|spam|money secret place|\n",
    "|non-spam|you know the secret|\n",
    "|?|secret coce to unlock money|\n",
    "\n",
    "* Calculate P(SpamC|\"secret code to unlock the money\"). Assign your answer to p_non_spam_given_message.\n",
    "* Print p_spam_given_message and p_non_spam_given_message. Why do you think we got these values? We'll discuss more about this in the next screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "p_spam = 2/4\n",
    "p_secret_given_spam = 4/7\n",
    "p_the_given_spam = 0/7\n",
    "p_money_given_spam = 2/7\n",
    "p_spam_given_message = (p_spam * p_secret_given_spam *\n",
    "                        p_the_given_spam * p_money_given_spam)\n",
    "p_non_spam = 2/4\n",
    "p_secret_given_non_spam = 2/9\n",
    "p_the_given_non_spam = 1/9\n",
    "p_money_given_non_spam = 0/9\n",
    "p_non_spam_given_message = (p_non_spam * p_secret_given_non_spam *\n",
    "                            p_the_given_non_spam * p_money_given_non_spam)\n",
    "\n",
    "\n",
    "print(p_spam_given_message)\n",
    "print(p_non_spam_given_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Additive Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we calculate P(Spam|\"secret code to unlock the money\"), we can see that P(\"the\"|Spam) is equal to 0 because \"the\" is not part of the spam messages. Unfortunately, that single value of 0 has the drawback of turning the result of the entire equation to 0:\n",
    "\n",
    "$\\begin{aligned}\n",
    "P(Spam|\\text{\"secret code to unlock the money\"}) &\\propto P(Spam) \\cdot P(\\text{\"secret\"}|Spam) \\cdot P(\\text{\"the\"}|Spam) \\cdot P(\\text{\"money\"}|Spam) \\\\\n",
    "&= \\frac{2}{4} \\cdot \\frac{4}{7} \\cdot \\frac{0}{7} \\cdot \\frac{2}{7} = 0\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`To fix this problem, we need to find a way to avoid these cases where we get probabilities of 0. Let's start by laying out the equation we're using to calculate P(\"the\"|Spam):`\n",
    "\n",
    "$\\begin{equation}\n",
    "P(\\text{\"the\"}|Spam) = \\frac{\\text{total number of times \"the\" occurs in spam messages}}{\\text{total number of words in spam messages}} = \\frac{0}{7}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to add some notation and rewrite the equation above as:\n",
    "\n",
    "$\\begin{equation}\n",
    "P(\\text{\"the\"}|Spam) = \\frac{N_{\\text{\"the\"}|Spam}}{N_{Spam}} = \\frac{0}{7}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the problem, we're going to use a technique called additive smoothing, where we add a smoothing parameter $\\alpha$. In the equation below, we'll use $\\alpha=1$ (below, NVocabulary represents the number of unique words in all the messages — both spam and non-spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(\\text{\"the\"}|Spam) = \\frac{N_{\\text{\"the\"}|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} = \\frac{0 + 1}{7 + 1 \\cdot 9} = \\frac{1}{16}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additive smoothing technique solves the issue and gets us a non-zero result, but it introduces another problem. We're now calculating probabilities differently depending on the word — take P(\"the\"|Spam) and P(\"secret\"|Spam) for instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    "P(\\text{\"the\"}|Spam) = \\frac{N_{\\text{\"the\"}|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(\\text{\"secret\"}|Spam) = \\frac{N_{\\text{\"secret\"}|Spam}}{N_{Spam}}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words like \"the\" are thus given special treatment and their probability are increased artificially to avoid non-zero cases, while words like \"secret\" are treated normally. To keep the probability values proportional across all words, we're going to use the additive smoothing for every word:\n",
    "\n",
    "$\\begin{equation}\n",
    "P(\\text{\"the\"}|Spam) = \\frac{N_{\\text{\"the\"}|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(\\text{\"secret\"}|Spam) = \\frac{N_{\\text{\"secret\"}|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more general terms, this is the equation that we'll need to use for every word:\n",
    "\n",
    "# $\\begin{equation}\n",
    "P(word|Spam) = \\frac{N_{\\text{word}|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, when $\\alpha=1$, the additive smoothing technique is most commonly known as` Laplace smoothing (or add-one smoothing).` However, it is also possible to use $\\alpha<1$, in which case the technique is called `Lidstone smoothing. `If you want to learn more about additive smoothing, you can start [here](https://en.wikipedia.org/wiki/Additive_smoothing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = 2/4\n",
    "p_secret_given_spam = (4 + 1) / (7 + 9)\n",
    "p_the_given_spam = (0 + 1) / (7 + 9)\n",
    "p_money_given_spam = (2 + 1) / (7 + 9)\n",
    "p_spam_given_message = (p_spam * p_secret_given_spam *\n",
    "                        p_the_given_spam * p_money_given_spam)\n",
    "p_non_spam = 2/4\n",
    "p_secret_given_non_spam = (2 + 1) / (9 + 9)\n",
    "p_the_given_non_spam = (1 + 1) / (9 + 9)\n",
    "p_money_given_non_spam = (0 + 1) / (9 + 9)\n",
    "p_non_spam_given_message = (p_non_spam * p_secret_given_non_spam *\n",
    "                            p_the_given_non_spam * p_money_given_non_spam)\n",
    "\n",
    "classification = 'spam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes algorithm can be used for more than just building spam filters. For instance, we could use it to perform sentiment analysis for Twitter messages — the input is a Twitter message, and the output is the sentiment type (positive or negative). This follows the same pattern we saw with our spam filter, where the input is a new SMS message and the output is the message type (spam or non-spam).\n",
    "\n",
    "Depending on the math and the assumptions used, the Naive Bayes algorithm has a few variations. The three most popular Naive Bayes algorithms are:\n",
    "\n",
    "* Multinomial Naive Bayes\n",
    "* Gaussian Naive Bayes\n",
    "* Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.**To summarize everything we've done so far, these are the two equations we can use for our spam filtering problem moving forward:**\n",
    "\n",
    "$\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}$\n",
    "\n",
    "$\\begin{equation}\n",
    "P(Spam^C | w_1,w_2, ..., w_n) \\propto P(Spam^C) \\cdot \\prod_{i=1}^{n}P(w_i|Spam^C)\n",
    "\\end{equation}$\n",
    "\n",
    "\n",
    "2.**To calculate P(wi|Spam) and P(wi|SpamC), we need to use the additive smoothing technique:**\n",
    "\n",
    "\n",
    "$\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}$\n",
    "\n",
    "$\\begin{equation}\n",
    "P(w_i|Spam^C) = \\frac{N_{w_i|Spam^C} + \\alpha}{N_{Spam^C} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also summarize what the terms in the equations above mean:\n",
    "\n",
    "$\\begin{aligned}\n",
    "&N_{w_i|Spam} = \\text{the number of times the word } w_i \\text{ occurs in spam messages} \\\\\n",
    "&N_{w_i|Spam^C} = \\text{the number of times the word } w_i \\text{ occurs in non-spam messages} \\\\\n",
    "\\\\\n",
    "&N_{Spam} = \\text{total number of words in spam messages} \\\\\n",
    "&N_{Spam^C} = \\text{total number of words in non-spam messages} \\\\\n",
    "\\\\\n",
    "&N_{Vocabulary} = \\text{total number of words in the vocabulary} \\\\\n",
    "&\\alpha = 1 \\ \\ \\ \\ (\\alpha \\text{ is a smoothing parameter})\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth emphasizing that:\n",
    "\n",
    "NSpam is equal to the number of words in all the spam messages — it's not equal to the number of spam messages, and it's not equal to the total number of unique words in spam messages.\n",
    "NSpamC is equal to the number of words in all the non-spam messages — it's not equal to the number of non-spam messages, and it's not equal to the total number of unique words in non-spam messages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
